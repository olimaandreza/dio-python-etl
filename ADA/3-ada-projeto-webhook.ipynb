{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a474535-6e52-4c5f-aff1-bff1622c2ef1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Projeto desenvolvido por Andreza Lima no âmbito do módulo de Extração de Dados I, na trilha de Engenharia de dados do programa Santander Coders 2023, em parceria com a Ada Tech.\n",
    "\n",
    "Desenvolvido com Databricks Community edition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72d01d8f-872e-44c7-aa88-7383aad97947",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Projeto Sistema de Monitoramento de Avanços no Campo da Genômica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e822efd7-9cad-4f8e-a5d1-e5646c983095",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Contexto:\n",
    "\n",
    "O grupo trabalha no time de engenharia de dados na HealthGen, uma empresa especializada em genômica e pesquisa de medicina personalizada. A genômica é o estudo do conjunto completo de genes de um organismo, desempenha um papel fundamental na medicina personalizada e na pesquisa biomédica. Permite a análise do DNA para identificar variantes genéticas e mutações associadas a doenças e facilita a personalização de tratamentos com base nas características genéticas individuais dos pacientes.\n",
    "\n",
    "A empresa precisa se manter atualizada sobre os avanços mais recentes na genômica, identificar oportunidades para pesquisa e desenvolvimento de tratamentos personalizados e acompanhar as tendências em genômica que podem influenciar estratégias de pesquisa e desenvolvimento. Pensando nisso, o time de dados apresentou uma proposta de desenvolvimento de um sistema que coleta, analisa e apresenta as últimas notícias relacionadas à genômica e à medicina personalizada, e também estuda o avanço do campo nos últimos anos. \n",
    "\n",
    "O time de engenharia de dados tem como objetivo desenvolver e garantir um pipeline de dados confiável e estável. As principais atividades são:\n",
    "\n",
    "1. Consumo de dados com a News API: \n",
    "Implementar um mecanismo para consumir dados de notícias de fontes confiáveis e especializadas em genômica e medicina personalizada, a partir da News API: \n",
    "https://newsapi.org/\n",
    "\n",
    "2. Definir Critérios de Relevância:\n",
    "Desenvolver critérios precisos de relevância para filtrar as notícias. Por exemplo, o time pode se concentrar em notícias que mencionem avanços em sequenciamento de DNA, terapias genéticas personalizadas ou descobertas relacionadas a doenças genéticas específicas.\n",
    "\n",
    "3. Cargas em Batches:\n",
    "Armazenar as notícias relevantes em um formato estruturado e facilmente acessível para consultas e análises posteriores. Essa carga deve acontecer 1 vez por hora. Se as notícias extraídas já tiverem sidos armazenadas na carga anterior, o processo deve ignorar e não armazenar as notícias novamente, os dados carregados não podem ficar duplicados.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1QLZBxgK4c4_yysUnvtamuwXzRJm4nNit\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "4. Dados transformados para consulta do público final:\n",
    "A partir dos dados carregados, aplicar as seguintes transformações e armazenar o resultado final para a consulta do público final:\n",
    "\n",
    "    4.1 - Quantidade de notícias por ano, mês e dia de publicação;\n",
    "\n",
    "    4.2 - Quantidade de notícias por fonte e autor;\n",
    "    \n",
    "    4.3 - Quantidade de aparições de 3 palavras chaves por ano, mês e dia de publicação (as 3 palavras chaves serão as mesmas usadas para fazer os filtros de relevância do item 2 (2. Definir Critérios de Relevância)).\n",
    "\n",
    "Atualizar os dados transformados 1 vez por dia.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1QOFkzKrWqb-9CY3kC3_1XkTWNVNE05dd\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "Além das atividades principais, existe a necessidade de busca de dados por eventos em tempo real quando é necessário, para isso foi desenhado duas opções:\n",
    "\n",
    "Opção 1 - Apache Kafka e Spark Streaming:\n",
    "\n",
    "Preparar um pipeline com Apache Kafka e Spark Streaming para receber os dados do Produtor Kafka representado por um evento manual e consumir os dados com o Spark Streaming armazenando os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1PvAxBXU0fvwEtJg36ZJ1VfBVSGETBpUZ\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Opção 2 - Webhooks com notificações por eventos:\n",
    "\n",
    "Configurar um webhook para adquirir as últimas notícias a partir de um evento representado por uma requisição POST e fazer a chamada da API e por fim armazenar os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1Px6Jp3aNuF-wpn_9earonylEMebzOcBW\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "## Atividades que precisam ser realizadas pelo grupo:\n",
    "\n",
    "O grupo precisa construir o pipeline de dados seguindo os requisitos das atividades principais e escolher entre a Opção 1 e Opção 2 para desenvolvimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f21d5970-c76d-4285-984c-19c80609cfae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Proposta de Resolução\n",
    "\n",
    "A execução deste projeto foi dividida em 5 arquivos.\n",
    "\n",
    "1-ada-projeto-load-data: contém os passos necessários para carregamento dos dados de hora em hora\n",
    "\n",
    "2-ada-projeto-transform-data: contém os passos necessários para transformação do arquivo consolidado, a cada 24 horas\n",
    "\n",
    "3-ada-projeto-webhook (este arquivo): cria uma aplicação flask para o processo de webhook\n",
    "\n",
    "4-ada-projeto-load-temp-data: contém os passos necessários para carregamento dos dados em uma pasta temporária, e depois carregamento no arquivo principal\n",
    "\n",
    "5-ada-projeto-webhook-post: envia post commands para a aplicação criada no arquivo 3-ada-projeto-webhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9025ae3d-0ad4-4992-855c-6d281f44a499",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e06e2af8-448e-4b9f-8120-d7b548249e37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\r\n  Using cached flask-2.3.3-py3-none-any.whl (96 kB)\r\nCollecting importlib-metadata>=3.6.0\r\n  Using cached importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\r\nCollecting Werkzeug>=2.3.7\r\n  Using cached werkzeug-2.3.7-py3-none-any.whl (242 kB)\r\nCollecting click>=8.1.3\r\n  Using cached click-8.1.7-py3-none-any.whl (97 kB)\r\nCollecting itsdangerous>=2.1.2\r\n  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\r\nCollecting blinker>=1.6.2\r\n  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\r\nCollecting Jinja2>=3.1.2\r\n  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\r\nCollecting zipp>=0.5\r\n  Using cached zipp-3.17.0-py3-none-any.whl (7.4 kB)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.9/site-packages (from Jinja2>=3.1.2->flask) (2.0.1)\r\nCollecting MarkupSafe>=2.0\r\n  Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\nInstalling collected packages: zipp, MarkupSafe, Werkzeug, Jinja2, itsdangerous, importlib-metadata, click, blinker, flask\r\n  Attempting uninstall: MarkupSafe\r\n    Found existing installation: MarkupSafe 2.0.1\r\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ada57206-40a6-48e5-90d4-c6cf84b21cf1\r\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\r\n  Attempting uninstall: Jinja2\r\n    Found existing installation: Jinja2 2.11.3\r\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ada57206-40a6-48e5-90d4-c6cf84b21cf1\r\n    Can't uninstall 'Jinja2'. No files were found to uninstall.\r\n  Attempting uninstall: click\r\n    Found existing installation: click 8.0.4\r\n    Not uninstalling click at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ada57206-40a6-48e5-90d4-c6cf84b21cf1\r\n    Can't uninstall 'click'. No files were found to uninstall.\r\nSuccessfully installed Jinja2-3.1.2 MarkupSafe-2.1.3 Werkzeug-2.3.7 blinker-1.6.2 click-8.1.7 flask-2.3.3 importlib-metadata-6.8.0 itsdangerous-2.1.2 zipp-3.17.0\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-ada57206-40a6-48e5-90d4-c6cf84b21cf1/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "## Executar apenas se for necessário instalar pacotes\n",
    "# !pip install pyspark\n",
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b782f1b-4496-432c-9921-68f099b4182e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import flask\n",
    "import json\n",
    "import pyspark.pandas as ps\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f6dbb96-2b59-4f6b-b9db-25a17eb6169d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Consumo de dados com a News API\n",
    "\n",
    "As etapas completas estão no arquivo 1-ada-projeto-load-data, mas aqui será necessário consumir a mesma função get_news, do arquivo funcoes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "207a7a8e-e703-4366-a4d6-c07d381e5192",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definindo a API_KEY\n",
    "API_KEY = \"281c2d765d504d18bffff38dbd5cd23a\" # Substituir para executar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e3bc82a-4653-4fe4-a7f2-03bb139bfae0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/olimaandreza@gmail.com/funcoes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc82d63a-d69c-4f83-a2a9-4080fa4d0822",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Definir Critérios de Relevância\n",
    "\n",
    "De acordo com Antunes (2022)¹, após cerca de 20 anos depois da publicação do primeiro rascunho da sequência de todo o genoma humano, os investigadores da área mergulharam na era “pós-genómica”, remodelando a investigação biológica e abrindo portas para a chamada medicina personalizada ou medicina de precisão, que pesquisa como medicamentos podem ser adaptados de um modo preciso, proporcionando o melhor tratamento possível através da sequenciação do genoma de cada indivíduo.\n",
    "\n",
    "Tendo como base essa discussão sobre os avanços da genômica, as palavras-chave escolhidas para este projeto foram os termos em inglês *genomics*, *precision medicine* e *personalized medicine*.\n",
    "\n",
    "¹ Antunes, A., (2022) Avanços da genómica, Rev. Ciência Elem., V10(4):056. Disponível em: https://rce.casadasciencias.org/rceapp/art/2022/056/. Acesso em: 25 set. 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ebd77c8-311c-4434-a93e-20ac7c120759",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Cargas em Batches:\n",
    "\n",
    "Ir para o arquivo 1-ada-projeto-load-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ba943cd-971a-4995-b66a-815d0dfc87a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Dados transformados para consulta do público final:\n",
    "A partir dos dados carregados, aplicar as seguintes transformações e armazenar o resultado final para a consulta do público final:\n",
    "\n",
    "    4.1 - Quantidade de notícias por ano, mês e dia de publicação;\n",
    "\n",
    "    4.2 - Quantidade de notícias por fonte e autor;\n",
    "    \n",
    "    4.3 - Quantidade de aparições de 3 palavras chaves por ano, mês e dia de publicação (as 3 palavras chaves serão as mesmas usadas para fazer os filtros de relevância do item 2 (2. Definir Critérios de Relevância)).\n",
    "\n",
    "Atualizar os dados transformados 1 vez por dia.\n",
    "\n",
    "Ir para o arquivo 2-ada-projeto-transform-data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74efc029-dfde-401d-a0ed-b3eb6f5e06b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Opção 2 - Webhooks com notificações por eventos:\n",
    "\n",
    "Webhook é uma forma de automação de comunicação entre sistemas. É um método que permite que um sistema envie automaticamente dados ou informações para outro sistema assim que um evento específico ocorrer. \n",
    "\n",
    "Para fins deste projeto, será criada uma aplicação com flask para simular um evento que ocorre sempre que um post command é executado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c05a413e-098a-403d-a277-45cd1855d95c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Criação de uma aplicação flask para simular um evento\n",
    "\n",
    "Configurar um webhook para adquirir as últimas notícias a partir de um evento representado por uma requisição POST e fazer a chamada da API e por fim armazenar os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a65c7753-3f3c-40a5-832b-c0b75d8dead9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n * Debug mode: off\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001B[31m\u001B[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001B[0m\n * Running on http://127.0.0.1:5000\nINFO:werkzeug:\u001B[33mPress CTRL+C to quit\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received data: {'message': 'Executar'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 19:37:10] \"POST /webhook HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo temporário salvo.\nReceived data: {'message': 'Executar'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 20:14:30] \"POST /webhook HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo temporário salvo.\nReceived data: {'message': 'Executar'}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [29/Sep/2023 20:14:35] \"POST /webhook HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo temporário salvo.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inicialização da aplicação Flask\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "# Definição da rota \"/webhook\" com suporte a requisições HTTP POST\n",
    "# Quando um post command for executado, vai executar a função handle_webhook()\n",
    "@app.route(\"/webhook\", methods=[\"POST\"])\n",
    "def handle_webhook():\n",
    "    # Define variáveis para o acesso à API e carregamento dos dados\n",
    "    keyword = 'genomics OR \"precision medicine\" OR \"personalized medicine\"'\n",
    "    api_key = \"281c2d765d504d18bffff38dbd5cd23a\" # Substituir chave para executar\n",
    "    dir_escrita_bruto_temp = \"/FileStore/projeto/temp/dados_tmp_\"\n",
    "\n",
    "    # Recupera o conteúdo da requisição como um dicionário em Python\n",
    "    data = flask.request.get_json()\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "   # Imprime o conteúdo da requisição\n",
    "    print(\"Received data:\", data)\n",
    "\n",
    "    # Se o conteúdo da mensagem for \"Executar\", faz o carregamento dos dados.\n",
    "    if data.get(\"message\") == \"Executar\":\n",
    "        df_temp = get_news(keyword,api_key)\n",
    "        df_temp.to_parquet(dir_escrita_bruto_temp+timestamp+\".parquet\")\n",
    "        \n",
    "    # Retorna uma resposta HTTP simples\n",
    "        print(\"Arquivo temporário salvo.\")\n",
    "        return \"OK\"\n",
    "    else:\n",
    "        print(\"Nenhum arquivo recebido.\")\n",
    "        return None\n",
    "\n",
    "# Verifica se o script está sendo executado como um módulo principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Inicia a execução da aplicação\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aa5789f-0fcc-48cb-849b-75ddc1b00d80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Carregamento de dados temporários\n",
    "\n",
    "Ir para o arquivo 4-ada-projeto-load-temp-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9f86b4a-122f-45e7-b01e-f1e54cb9a745",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Execução do post command\n",
    "\n",
    "Ir para o arquivo 5-ada-projeto-webhook-post"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1958246452001375,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3-ada-projeto-webhook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
