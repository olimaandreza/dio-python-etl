{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a474535-6e52-4c5f-aff1-bff1622c2ef1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Projeto desenvolvido por Andreza Lima no âmbito do módulo de Extração de Dados I, na trilha de Engenharia de dados do programa Santander Coders 2023, em parceria com a Ada Tech.\n",
    "\n",
    "Desenvolvido com Databricks Community edition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72d01d8f-872e-44c7-aa88-7383aad97947",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Projeto Sistema de Monitoramento de Avanços no Campo da Genômica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e822efd7-9cad-4f8e-a5d1-e5646c983095",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Contexto:\n",
    "\n",
    "O grupo trabalha no time de engenharia de dados na HealthGen, uma empresa especializada em genômica e pesquisa de medicina personalizada. A genômica é o estudo do conjunto completo de genes de um organismo, desempenha um papel fundamental na medicina personalizada e na pesquisa biomédica. Permite a análise do DNA para identificar variantes genéticas e mutações associadas a doenças e facilita a personalização de tratamentos com base nas características genéticas individuais dos pacientes.\n",
    "\n",
    "A empresa precisa se manter atualizada sobre os avanços mais recentes na genômica, identificar oportunidades para pesquisa e desenvolvimento de tratamentos personalizados e acompanhar as tendências em genômica que podem influenciar estratégias de pesquisa e desenvolvimento. Pensando nisso, o time de dados apresentou uma proposta de desenvolvimento de um sistema que coleta, analisa e apresenta as últimas notícias relacionadas à genômica e à medicina personalizada, e também estuda o avanço do campo nos últimos anos. \n",
    "\n",
    "O time de engenharia de dados tem como objetivo desenvolver e garantir um pipeline de dados confiável e estável. As principais atividades são:\n",
    "\n",
    "1. Consumo de dados com a News API: \n",
    "Implementar um mecanismo para consumir dados de notícias de fontes confiáveis e especializadas em genômica e medicina personalizada, a partir da News API: \n",
    "https://newsapi.org/\n",
    "\n",
    "2. Definir Critérios de Relevância:\n",
    "Desenvolver critérios precisos de relevância para filtrar as notícias. Por exemplo, o time pode se concentrar em notícias que mencionem avanços em sequenciamento de DNA, terapias genéticas personalizadas ou descobertas relacionadas a doenças genéticas específicas.\n",
    "\n",
    "3. Cargas em Batches:\n",
    "Armazenar as notícias relevantes em um formato estruturado e facilmente acessível para consultas e análises posteriores. Essa carga deve acontecer 1 vez por hora. Se as notícias extraídas já tiverem sidos armazenadas na carga anterior, o processo deve ignorar e não armazenar as notícias novamente, os dados carregados não podem ficar duplicados.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1QLZBxgK4c4_yysUnvtamuwXzRJm4nNit\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "4. Dados transformados para consulta do público final:\n",
    "A partir dos dados carregados, aplicar as seguintes transformações e armazenar o resultado final para a consulta do público final:\n",
    "\n",
    "    4.1 - Quantidade de notícias por ano, mês e dia de publicação;\n",
    "\n",
    "    4.2 - Quantidade de notícias por fonte e autor;\n",
    "    \n",
    "    4.3 - Quantidade de aparições de 3 palavras chaves por ano, mês e dia de publicação (as 3 palavras chaves serão as mesmas usadas para fazer os filtros de relevância do item 2 (2. Definir Critérios de Relevância)).\n",
    "\n",
    "Atualizar os dados transformados 1 vez por dia.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1QOFkzKrWqb-9CY3kC3_1XkTWNVNE05dd\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "Além das atividades principais, existe a necessidade de busca de dados por eventos em tempo real quando é necessário, para isso foi desenhado duas opções:\n",
    "\n",
    "Opção 1 - Apache Kafka e Spark Streaming:\n",
    "\n",
    "Preparar um pipeline com Apache Kafka e Spark Streaming para receber os dados do Produtor Kafka representado por um evento manual e consumir os dados com o Spark Streaming armazenando os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1PvAxBXU0fvwEtJg36ZJ1VfBVSGETBpUZ\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Opção 2 - Webhooks com notificações por eventos:\n",
    "\n",
    "Configurar um webhook para adquirir as últimas notícias a partir de um evento representado por uma requisição POST e fazer a chamada da API e por fim armazenar os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1Px6Jp3aNuF-wpn_9earonylEMebzOcBW\"  width=\"70%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "## Atividades que precisam ser realizadas pelo grupo:\n",
    "\n",
    "O grupo precisa construir o pipeline de dados seguindo os requisitos das atividades principais e escolher entre a Opção 1 e Opção 2 para desenvolvimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f21d5970-c76d-4285-984c-19c80609cfae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Proposta de Resolução\n",
    "\n",
    "A execução deste projeto foi dividida em 5 arquivos.\n",
    "\n",
    "1-ada-projeto-load-data (este arquivo): contém os passos necessários para carregamento dos dados de hora em hora\n",
    "\n",
    "2-ada-projeto-transform-data: contém os passos necessários para transformação do arquivo consolidado, a cada 24 horas\n",
    "\n",
    "3-ada-projeto-webhook: cria uma aplicação flask para o processo de webhook\n",
    "\n",
    "4-ada-projeto-load-temp-data: contém os passos necessários para carregamento dos dados em uma pasta temporária, e depois carregamento no arquivo principal\n",
    "\n",
    "5-ada-projeto-webhook-post: envia post commands para a aplicação criada no arquivo 3-ada-projeto-webhook\n",
    "\n",
    "Além destes, um arquivo funcoes.ipynb foi criado para guardar apenas as funções compartilhadas entre notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9025ae3d-0ad4-4992-855c-6d281f44a499",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e06e2af8-448e-4b9f-8120-d7b548249e37",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\r\n  Downloading flask-2.3.3-py3-none-any.whl (96 kB)\r\n\u001B[?25l\r\u001B[K     |███▍                            | 10 kB 23.3 MB/s eta 0:00:01\r\u001B[K     |██████▉                         | 20 kB 7.6 MB/s eta 0:00:01\r\u001B[K     |██████████▎                     | 30 kB 10.4 MB/s eta 0:00:01\r\u001B[K     |█████████████▋                  | 40 kB 5.9 MB/s eta 0:00:01\r\u001B[K     |█████████████████               | 51 kB 5.2 MB/s eta 0:00:01\r\u001B[K     |████████████████████▌           | 61 kB 6.0 MB/s eta 0:00:01\r\u001B[K     |███████████████████████▉        | 71 kB 6.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▎    | 81 kB 5.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▊ | 92 kB 5.9 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 96 kB 3.0 MB/s \r\n\u001B[?25hCollecting importlib-metadata>=3.6.0\r\n  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\r\nCollecting Werkzeug>=2.3.7\r\n  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\r\n\u001B[?25l\r\u001B[K     |█▍                              | 10 kB 29.3 MB/s eta 0:00:01\r\u001B[K     |██▊                             | 20 kB 31.6 MB/s eta 0:00:01\r\u001B[K     |████                            | 30 kB 36.9 MB/s eta 0:00:01\r\u001B[K     |█████▍                          | 40 kB 35.7 MB/s eta 0:00:01\r\u001B[K     |██████▊                         | 51 kB 5.9 MB/s eta 0:00:01\r\u001B[K     |████████▏                       | 61 kB 7.0 MB/s eta 0:00:01\r\u001B[K     |█████████▌                      | 71 kB 7.9 MB/s eta 0:00:01\r\u001B[K     |██████████▉                     | 81 kB 8.8 MB/s eta 0:00:01\r\u001B[K     |████████████▏                   | 92 kB 9.7 MB/s eta 0:00:01\r\u001B[K     |█████████████▌                  | 102 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |██████████████▉                 | 112 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |████████████████▎               | 122 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |█████████████████▋              | 133 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |███████████████████             | 143 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |████████████████████▎           | 153 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |█████████████████████▋          | 163 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |███████████████████████         | 174 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |████████████████████████▍       | 184 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▊      | 194 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████     | 204 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████▍   | 215 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▊  | 225 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▏| 235 kB 6.2 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 242 kB 6.2 MB/s \r\n\u001B[?25hCollecting click>=8.1.3\r\n  Downloading click-8.1.7-py3-none-any.whl (97 kB)\r\n\u001B[?25l\r\u001B[K     |███▍                            | 10 kB 21.2 MB/s eta 0:00:01\r\u001B[K     |██████▊                         | 20 kB 23.9 MB/s eta 0:00:01\r\u001B[K     |██████████                      | 30 kB 29.2 MB/s eta 0:00:01\r\u001B[K     |█████████████▍                  | 40 kB 31.9 MB/s eta 0:00:01\r\u001B[K     |████████████████▊               | 51 kB 31.9 MB/s eta 0:00:01\r\u001B[K     |████████████████████            | 61 kB 34.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████████▍        | 71 kB 35.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████████████▊     | 81 kB 37.0 MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▏ | 92 kB 36.9 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 97 kB 8.4 MB/s \r\n\u001B[?25hCollecting itsdangerous>=2.1.2\r\n  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\r\nCollecting blinker>=1.6.2\r\n  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\r\nCollecting Jinja2>=3.1.2\r\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\r\n\u001B[?25l\r\u001B[K     |██▌                             | 10 kB 26.4 MB/s eta 0:00:01\r\u001B[K     |█████                           | 20 kB 29.6 MB/s eta 0:00:01\r\u001B[K     |███████▍                        | 30 kB 33.7 MB/s eta 0:00:01\r\u001B[K     |█████████▉                      | 40 kB 36.3 MB/s eta 0:00:01\r\u001B[K     |████████████▎                   | 51 kB 38.6 MB/s eta 0:00:01\r\u001B[K     |██████████████▊                 | 61 kB 41.6 MB/s eta 0:00:01\r\u001B[K     |█████████████████▎              | 71 kB 43.7 MB/s eta 0:00:01\r\u001B[K     |███████████████████▊            | 81 kB 45.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████████▏         | 92 kB 46.1 MB/s eta 0:00:01\r\u001B[K     |████████████████████████▋       | 102 kB 46.7 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████     | 112 kB 46.7 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▌  | 122 kB 46.7 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 133 kB 46.7 MB/s \r\n\u001B[?25hCollecting zipp>=0.5\r\n  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.9/site-packages (from Jinja2>=3.1.2->flask) (2.0.1)\r\nCollecting MarkupSafe>=2.0\r\n  Downloading MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\nInstalling collected packages: zipp, MarkupSafe, Werkzeug, Jinja2, itsdangerous, importlib-metadata, click, blinker, flask\r\n  Attempting uninstall: MarkupSafe\r\n    Found existing installation: MarkupSafe 2.0.1\r\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7786b549-3085-40a3-8a71-9d80231bf366\r\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\r\n  Attempting uninstall: Jinja2\r\n    Found existing installation: Jinja2 2.11.3\r\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7786b549-3085-40a3-8a71-9d80231bf366\r\n    Can't uninstall 'Jinja2'. No files were found to uninstall.\r\n  Attempting uninstall: click\r\n    Found existing installation: click 8.0.4\r\n    Not uninstalling click at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7786b549-3085-40a3-8a71-9d80231bf366\r\n    Can't uninstall 'click'. No files were found to uninstall.\r\nSuccessfully installed Jinja2-3.1.2 MarkupSafe-2.1.3 Werkzeug-2.3.7 blinker-1.6.2 click-8.1.7 flask-2.3.3 importlib-metadata-6.8.0 itsdangerous-2.1.2 zipp-3.17.0\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-7786b549-3085-40a3-8a71-9d80231bf366/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "## Executar apenas se for necessário instalar pacotes\n",
    "# !pip install pyspark\n",
    "# !pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b782f1b-4496-432c-9921-68f099b4182e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# import flask\n",
    "import json\n",
    "import pyspark.pandas as ps\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0c373f9-8fda-467f-ac4d-54b012c6b44d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/olimaandreza@gmail.com/funcoes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2eab63e7-5072-4055-b62d-4a555a72f676",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Consumo de dados com a News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2304704c-d5da-475d-b3eb-5238c45f7671",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definindo a API_KEY\n",
    "API_KEY = \"281c2d765d504d18bffff38dbd5cd23a\" # Substituir para executar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5c00478-8f6e-457f-b2e7-40a315a3efb4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Definir Critérios de Relevância\n",
    "\n",
    "De acordo com Antunes (2022)¹, após cerca de 20 anos depois da publicação do primeiro rascunho da sequência de todo o genoma humano, os investigadores da área mergulharam na era “pós-genómica”, remodelando a investigação biológica e abrindo portas para a chamada medicina personalizada ou medicina de precisão, que pesquisa como medicamentos podem ser adaptados de um modo preciso, proporcionando o melhor tratamento possível através da sequenciação do genoma de cada indivíduo.\n",
    "\n",
    "Tendo como base essa discussão sobre os avanços da genômica, as palavras-chave escolhidas para este projeto foram os termos em inglês *genomics*, *precision medicine* e *personalized medicine*.\n",
    "\n",
    "¹ Antunes, A., (2022) Avanços da genómica, Rev. Ciência Elem., V10(4):056. Disponível em: https://rce.casadasciencias.org/rceapp/art/2022/056/. Acesso em: 25 set. 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56dd56e2-d5b1-4efb-a31e-d4687dec6fc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Cargas em Batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26657537-22ed-4c9c-a600-b4dc22c3b010",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definindo variáveis para o load_data\n",
    "\n",
    "tempo_proc_load_data = 1* 60 #* 60 # 1 hora * 60 minutos * 60 segundos\n",
    "keyword = 'genomics OR \"precision medicine\" OR \"personalized medicine\"'\n",
    "api_key = API_KEY # Substituir chave para executar\n",
    "dir_escrita_bruto = \"/FileStore/projeto/dados_consolidados.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a8c3a7-381e-4e65-805c-1ffa8675738d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:27:45: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:29:02: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:30:17: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:31:28: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:32:37: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:33:51: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:35:08: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:36:23: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:37:41: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:38:59: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\n>Arquivo não encontrado, primeiro processamento.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:40:23: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:41:39: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:42:54: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:44:09: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:45:25: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:46:41: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:47:56: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:49:12: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:50:27: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:51:43: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:52:58: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:54:08: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:55:17: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:56:28: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:57:37: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 19:58:53: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 20:00:14: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 20:01:31: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 20:02:47: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n\n2023-09-29 20:04:03: Próxima verificação em 1.0 minuto(s).\n\nIniciando verificação\n\nIniciando carregamento de dados.\n\n> Arquivo já existe. Iniciando leitura do arquivo existente.\n\n>Fim da leitura do arquivo existente.\n\n>Iniciando concatenação do novo arquivo.\n\n>Novo arquivo concatenado com sucesso.\n\n>Removendo duplicados do arquivo\n\n>Iniciando salvamento do novo arquivo.\n\nResultado carregado com sucesso\n---------------------------\n"
     ]
    }
   ],
   "source": [
    "# Carrega os dados em um primeiro momento\n",
    "load_data(get_news(keyword,api_key), dir_escrita_bruto)\n",
    "\n",
    "# Inicia o loop que chama a função load_data a cada tempo_proc_load_data\n",
    "contador_load_data = 0 # Limitar para testes\n",
    "\n",
    "# Inicia o a cada tempo_proc_load_data\n",
    "while contador_load_data < 30:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(\"\\n\" + timestamp+ f\": Próxima verificação em {tempo_proc_load_data/60} minuto(s).\")\n",
    "    time.sleep(tempo_proc_load_data)\n",
    "    print(\"\\nIniciando verificação\")\n",
    "    load_data(get_news(keyword,api_key), dir_escrita_bruto)\n",
    "    contador_load_data +=1 # Comentar esta linha para rodar infinitamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e2def2b-4e10-4e25-83ce-163558e26424",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfteste = ps.read_parquet(dir_escrita_bruto) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81fbbf49-9b10-4985-a41e-a71e1daeb82e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.pandas.frame.DataFrame'>\nInt64Index: 93 entries, 0 to 92\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   source_name      93 non-null     object\n 1   author           78 non-null     object\n 2   title            93 non-null     object\n 3   description      93 non-null     object\n 4   url              93 non-null     object\n 5   publishedAt      93 non-null     object\n 6   content          93 non-null     object\n 7   publishedAt_ano  93 non-null     object\n 8   publishedAt_mes  93 non-null     object\n 9   publishedAt_dia  93 non-null     object\ndtypes: object(10)"
     ]
    }
   ],
   "source": [
    "dfteste.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39ba82c0-a2f7-4f55-b8d2-2a22ec042358",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Dados transformados para consulta do público final:\n",
    "A partir dos dados carregados, aplicar as seguintes transformações e armazenar o resultado final para a consulta do público final:\n",
    "\n",
    "    4.1 - Quantidade de notícias por ano, mês e dia de publicação;\n",
    "\n",
    "    4.2 - Quantidade de notícias por fonte e autor;\n",
    "    \n",
    "    4.3 - Quantidade de aparições de 3 palavras chaves por ano, mês e dia de publicação (as 3 palavras chaves serão as mesmas usadas para fazer os filtros de relevância do item 2 (2. Definir Critérios de Relevância)).\n",
    "\n",
    "Atualizar os dados transformados 1 vez por dia.\n",
    "\n",
    "Ir para o arquivo 2-ada-projeto-transform-data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74efc029-dfde-401d-a0ed-b3eb6f5e06b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Opção 2 - Webhooks com notificações por eventos:\n",
    "\n",
    "Webhook é uma forma de automação de comunicação entre sistemas. É um método que permite que um sistema envie automaticamente dados ou informações para outro sistema assim que um evento específico ocorrer. \n",
    "\n",
    "Para fins deste projeto, será criada uma aplicação com flask para simular um evento que ocorre sempre que um post command é executado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c05a413e-098a-403d-a277-45cd1855d95c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Criação de uma aplicação flask para simular um evento\n",
    "\n",
    "Configurar um webhook para adquirir as últimas notícias a partir de um evento representado por uma requisição POST e fazer a chamada da API e por fim armazenar os resultados temporariamente. Em um processo paralelo, verificar os resultados armazenados temporiamente e armazenar no mesmo destino do item 3 (3. Cargas em Batches) aqueles resultados que ainda não foram armazenados no destino (os dados carregados não podem ficar duplicados). E por fim, eliminar os dados temporários após a verificação e a eventual carga.\n",
    "\n",
    "Ir para o arquivo 3-ada-projeto-webhook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e796c82-9555-4386-8ddd-7a7e305c2140",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Carregamento de dados temporários\n",
    "\n",
    "Ir para o arquivo 4-ada-projeto-load-temp-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a9c58ae-861c-4914-bb08-77865a09ce2f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Execução do post command\n",
    "\n",
    "Ir para o arquivo 5-ada-projeto-webhook-post"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1958246452001375,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1-ada-projeto-load-data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
